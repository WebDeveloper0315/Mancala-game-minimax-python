{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/blackghost1503/mancala-game-using-minimax?scriptVersionId=159152259\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"---\n\n# CSCI 3202, Fall 2023\n# Mancala Project - Outline\n","metadata":{}},{"cell_type":"code","source":"import copy, math, time, random\nfrom tqdm import tqdm # to show the progress bar\nrandom.seed(109)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T03:16:32.565737Z","iopub.execute_input":"2023-11-28T03:16:32.566159Z","iopub.status.idle":"2023-11-28T03:16:32.585755Z","shell.execute_reply.started":"2023-11-28T03:16:32.56612Z","shell.execute_reply":"2023-11-28T03:16:32.584462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. Play 100 games of random player against random player\n\n        Result:\n            Player 1 (Random) Wins: 47\n            Player 2 (Random) Wins: 49\n            Ties: 4\n            Average number of moves per game: 45.82\n    - What percentage of games does each player (1st or 2nd) win?\n    \n            Percentage of games does Player 1 win is 47%\n                                     Player 2        49%\n        \n    - On average, how many moves does it take to win?\n    \n            Average number of moves per game: 45.82\n2. Build an AI player that uses minimax to choose the best move with a variable number of plies and a utility function we describe\n\n        Result of 1 game:\n            Elapsed Time: 00:02\n            Player 1 (Random) Wins:0\n            Player 2 (AI - Minimax) Wins:1\n            Ties: 0\n            Average number of moves per game: 39.0\n    - What percentage of games does each player (AI or random) win?\n    \n            Percentage of games does Player 1 win is 100%\n                                     Player 2        0  %\n    \n    - On average, how many moves does it take to win?\n            \n            Average number of moves per game: 39.0\n3. Play 100 games with the random player against the minimax AI player at a depth of 5 plies\n\n        Result of 100 games:\n            Elapsed Time: 02:48\n            Player 1 (Random) Wins:0\n            Player 2 (AI - Minimax) Wins:100\n            Ties: 0\n            Average number of moves per game: 36.16\n    - What percentage of games does each player (AI or random) win?\n    \n            Percentage of games does Player 1 win is 100%\n                                     Player 2        0  %\n    - On average, how many moves does it take to win?\n            \n            Average number of moves per game: 32.9\n    - Is your AI player better than random chance? Write a paragraph or two describing why or why not.\n    \n            Minimax AI player is better than random chance, because the minimax algorithm makes optimal moves by considering all possible states with a certain depth (in this case, 5 plies). \n            On the other hand, the random player makes moves randomly without considering the strategic aspects. \n            Therefore, the minimax AI player's decision-making ability and strategic thinking is better than the random player.\n            \n4. Play 100 games with the random player against the Alpha-Beta AI player at a depth of 5 plies\n\n        Result of 100 games:\n            Elapsed Time: 00:45\n            Player 1 (AI) Wins: 100\n            Player 2 (Random) Wins: 0\n            Ties: 0\n            Average number of moves per game: 32.69\n    - How long does it take for a single game to run to completion?\n    \n            Running 100 games elapsed 45 seconds, so running a single game elapsed 0.45s = 450 ms.\n    - What percentage of games does each player (AI or random) win?\n    \n            Percentage of games does Player 1 win is 100%\n                                     Player 2        0  %\n    - On average, how many moves does it take to win?\n    \n            Average number of moves per game: 32.69\n    - Are your results for this part different from those for your minimax AI player? Write a paragraph or two describing why or why not.\n    \n            The results for the Alpha-Beta AI player are slightly better than the results for the minimax AI player.\n            This is because the Alpha-Beta algorithm is an enhancement of the minimax algorithm, that prunes unnecessary branches among the game tree, resulting in faster and more efficient decision-making. \n            By considering only the most promising moves, the Alpha-Beta AI player is able to make better decisions and achieve a slightly higher average number of moves per game. \n            But, by considering speed and efficiency part, the Alpha-Beta AI player outperforms the minimax AI player in terms of both speed and efficiency in decision-making.\n5. (Extra Credit, 10 points). Play 100 games with the random player against the Alpha-Beta AI player at a depth of 10 plies\n\n        Result of 100 games with depth of 10 plies\n            Elapsed Time: 1:33:26\n            Player 1 (AI) Wins: 100\n            Player 2 (Random) Wins: 0\n            Ties: 0\n            Average number of moves per game: 33.04\n    - How long does it take for a single game to run to completion?\n            \n            Running 100 games elapsed 1 hr 33mins 26seconds = 5606s, so running a single game elapsed 56.06s.\n    - What percentage of games does each player (AI or random) win?\n    \n            Percentage of games does Player 1 win is 100%\n                                     Player 2        0  %\n    - On average, how many moves does it take to win?\n    \n            Average number of moves per game: 33.04\n    - Does increasing the number of plies improve the play for our AI player? Why or why not?\n    \n            Yes, increasing the number of plies improves the play for our AI player because it allows the AI player to look ahead more and make better decisions, resulting in fewer moves to win on average. \n            However, increasing the depth also increases the time it takes to complete a game.\n\nexplanation for deepcopy - copy library\nhttps://www.scaler.com/topics/copy-in-python/","metadata":{}},{"cell_type":"code","source":"class Mancala:\n    def __init__(self, pits_per_player=6, stones_per_pit = 4):\n        self.pits_per_player = pits_per_player\n        self.board = [stones_per_pit] * ((pits_per_player + 1) * 2)\n        self.players = 2\n        self.current_player = 1\n        self.moves = []\n        self.p1_pits_index = [0, self.pits_per_player-1]\n        self.p1_mancala_index = self.pits_per_player\n        self.p2_pits_index = [self.pits_per_player + 1, len(self.board) - 2]\n        self.p2_mancala_index = len(self.board) - 1\n    \n        self.num_plays = 0\n        self.board[self.p1_mancala_index] = 0\n        self.board[self.p2_mancala_index] = 0\n        self.p1_wins = 0\n        self.p2_wins = 0\n        self.ties = 0\n\n        self.stones_per_pit = stones_per_pit\n        \n\n    def display_board(self):\n        player_1_pits = self.board[self.p1_pits_index[0]: self.p1_pits_index[1] + 1]\n        player_1_mancala = self.board[self.p1_mancala_index]\n        player_2_pits = self.board[self.p2_pits_index[0]: self.p2_pits_index[1] + 1]\n        player_2_mancala = self.board[self.p2_mancala_index]\n\n        print('P1               P2')\n        print('     ____{}____     '.format(player_2_mancala))\n        for i in range(self.pits_per_player):\n            if i == self.pits_per_player - 1:\n                print('{} -> |_{}_|_{}_| <- {}'.format(i + 1, player_1_pits[i], player_2_pits[-(i + 1)],\n                                                       self.pits_per_player - i))\n            else:\n                print('{} -> | {} | {} | <- {}'.format(i + 1, player_1_pits[i], player_2_pits[-(i + 1)],\n                                                      self.pits_per_player - i))\n\n        print('         {}         '.format(player_1_mancala))\n        turn = 'P1' if self.current_player == 1 else 'P2'\n        print('Turn: ' + turn)\n    \n    def random_move_generator(self):\n        \"\"\"\n        Function to generate random valid moves with non-empty pits for the random player\n        \"\"\"\n        if self.current_player == 1:\n            valid_moves = [i for i in range(0, self.pits_per_player) if self.board[i] > 0]\n        else:\n            valid_moves = [i for i in range(self.pits_per_player + 1, len(self.board) - 1) if self.board[i] > 0]\n        \n        if valid_moves:\n            return random.choice(valid_moves) + 1\n#             pit = random.randint(1, self.pits_per_player)    \n#             while not self.valid_move(pit):\n#                 pit = random.randint(1, self.pits_per_player)\n#             return pit\n        else:\n            return -1\n        \n        \n    def generate_board(self):\n        self.board = [self.stones_per_pit] * ((self.pits_per_player+1) * 2)\n        self.current_player = 1\n        self.moves = []\n        self.board[self.p1_mancala_index] = 0\n        self.board[self.p2_mancala_index] = 0\n\n    def valid_move(self, pit):\n        \"\"\"\n        Function to check if the pit chosen by the current_player is a valid move.\n        \"\"\"\n\n        pit_index = pit - 1 # + (self.current_player - 1) * (self.pits_per_player + 1) \n        current_player_pits_range = self.p1_pits_index if self.current_player == 1 else self.p2_pits_index\n\n        if pit_index < current_player_pits_range[0] or pit_index > current_player_pits_range[1] or self.board[pit_index] == 0:\n            return False\n        # self.moves.append([self.current_player, pit])\n        return True\n\n    def play(self, pit, cur_player, debug = False):\n        self.current_player = cur_player\n        if pit > 0:\n            if debug == True:\n                print('Player {} chose pit: {}\\n'.format(self.current_player, pit))\n            \n            if not self.valid_move(pit):\n                if debug == True:\n                    print(\"Invalid move\\n\")\n                return self.board\n\n            if self.winning_eval():\n                if debug == True:\n                    print('Game Over')\n                return self.board\n            \n            pit_index = pit - 1 #+ (self.current_player - 1) * (self.pits_per_player + 1)\n            stones_to_distribute = self.board[pit_index]\n            self.board[pit_index] = 0\n\n            while stones_to_distribute > 0:\n                pit_index = (pit_index + 1) % len(self.board)\n                if (self.current_player == 1 and pit_index == self.p2_mancala_index) or (self.current_player == 2 and pit_index == self.p1_mancala_index):\n                    continue  \n                self.board[pit_index] += 1\n                stones_to_distribute -= 1\n\n            if (self.current_player == 1 and pit_index >= self.p1_pits_index[0] and pit_index <= self.p1_pits_index[1] and self.board[pit_index] == 1) or (self.current_player == 2 and pit_index >= self.p2_pits_index[0] and pit_index <= self.p2_pits_index[1] and self.board[pit_index] == 1):\n                opposite_pit_index = len(self.board) - pit_index - 2\n                if self.board[opposite_pit_index] > 0:\n                    self.board[self.p1_mancala_index if self.current_player == 1 else self.p2_mancala_index] += self.board[opposite_pit_index] + 1\n                    self.board[opposite_pit_index] = 0\n                    self.board[pit_index] = 0\n\n        self.current_player = 1 if self.current_player == 2 else 2\n        return self.board \n        \n    def winning_eval(self):\n        \"\"\"\n        Function to verify if the game board has reached the winning state.\n        Hint: If either of the players' pits are all empty, then it is considered a winning state.\n        \"\"\"\n        p1_pits_sum = sum(self.board[self.p1_pits_index[0]: self.p1_pits_index[1] + 1])\n        p2_pits_sum = sum(self.board[self.p2_pits_index[0]: self.p2_pits_index[1] + 1])\n\n        # Game ends if any player's pits are all empty\n        if p1_pits_sum == 0 or p2_pits_sum == 0:\n            if self.board[self.p1_mancala_index] > self.board[self.p2_mancala_index]:\n                return \"Player 1\"\n            elif self.board[self.p1_mancala_index] < self.board[self.p2_mancala_index]:\n                return \"Player 2\"\n            else:\n                return \"Tie\"\n        return None\n    \n    def match_analysis(self, games = 100, debug = False, p1_type = 'random', p2_type = 'alpha-beta', p1_depth = 5, p2_depth = 5):\n        p1_wins = 0\n        p2_wins = 0\n        ties = 0\n        total_moves = 0\n#         p1_moves = 0\n#         p2_moves = 0\n\n        total_iterations = games # to show the progress bar\n\n        # Create a progress bar\n        progress_bar = tqdm(total=total_iterations) # to show the progress bar\n        \n        ai_p1 = MancalaAI(depth = p1_depth, state = self)\n        ai_p2 = MancalaAI(depth = p2_depth, state = self) \n\n        for game in range(games):\n            self.generate_board()\n            while self.winning_eval() is None: # while game is not over\n                if self.current_player == 1:\n                    if p1_type == 'random':\n                        move = self.random_move_generator() # Random Player\n                    else:\n                        move = ai_p1.best_move(self, p1_type == 'alpha-beta', self.current_player == 1)\n                else:\n                    if p2_type == 'random':\n                        move = self.random_move_generator() # Random Player\n                    else:\n                        move = ai_p2.best_move(self, p2_type == 'alpha-beta', self.current_player == 1)\n                    \n                old_cur_player = self.current_player\n                while old_cur_player == self.current_player:\n                    self.play(move, old_cur_player, debug)\n                    total_moves += 1\n                if debug:\n                    game.display_board()\n\n            winner = self.winning_eval() # determine winner\n\n            if winner == \"Player 1\":\n                p1_wins += 1\n            elif winner == \"Player 2\":\n                p2_wins += 1\n            else:\n                ties += 1\n\n            progress_bar.update(1) # to show the progress bar\n        progress_bar.close() # to show the progress bar\n        \n        p1_string = ''\n        p2_string = ''\n        \n        if p1_type == 'random':\n            p1_string = 'Random'\n        elif p1_type == 'minimax':\n            p1_string = 'AI - Minimax'\n        else:\n            p1_string = 'AI - Alpha-beta'\n        \n        if p2_type == 'random':\n            p2_string = 'Random'\n        elif p2_type == 'minimax':\n            p2_string = 'AI - Minimax'\n        else:\n            p2_string = 'AI - Alpha-beta'\n        print('Player 1 ({}) Wins:{}'.format(p1_string, p1_wins))\n        print('Player 2 ({}) Wins:{}'.format(p2_string, p2_wins))\n        print('Ties:', ties)\n        print('Average number of moves per game:', total_moves/games)\n#         print('Average number of Player 1\\'s moves per game:', p1_moves/games)\n#         print('Average number of Player 2\\'s moves per game:', p2_moves/games)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MancalaAI:\n    def __init__(self, depth, state):\n        self.depth = depth\n        self.state = copy.deepcopy(state)\n    \n    def minimax(self, state, depth, maximizing_player, cur_player):\n        if depth == 0 or state.winning_eval() is not None:  # terminal state \n            return self.evaluate_state(state), None  # return the evaluated score\n        if maximizing_player:\n            # generate all possible states for the maximizing player, and recurse \n            # until you reach the stop condition - terminal state\n            value = -math.inf\n            best_move = None  # to store the best move possible\n            for i in range(0, state.pits_per_player):  # generate all possible states\n                new_state = copy.deepcopy(state)  \n                if new_state.board[i] == 0: continue\n                new_state.play(i + 1, cur_player)  \n                new_score, _ = self.minimax(new_state, depth - 1, False, 3 - cur_player)  # recursive call\n                if new_score > value:  # maximizing the value\n                    value = new_score\n                    best_move = i + 1\n            return value, best_move\n        else:\n            # generate all possible states for the maximizing player, and recurse\n            value = math.inf\n            best_move = None  \n            for i in range(state.pits_per_player + 1, len(state.board) - 1):  # generate all possible states\n                new_state = copy.deepcopy(state)\n                if new_state.board[i] == 0: continue  \n                new_state.play(i + 1, cur_player)  \n                new_score, _ = self.minimax(new_state, depth - 1, True, 3 - cur_player)  # recursive call\n                if new_score < value:  # minimizing the value\n                    value = new_score\n                    best_move = i + 1\n            return value, best_move\n    \n    def minimax_alpha_beta(self, state, depth, alpha, beta, maximizing_player, cur_player):\n        if depth == 0 or state.winning_eval() is not None:  # terminal state \n            return self.evaluate_state(state), None  # return the evaluated score\n        if maximizing_player:\n            value = -math.inf\n            best_move = None\n            for i in range(0, state.pits_per_player):  # generate all possible states\n                new_state = copy.deepcopy(state)\n                if new_state.board[i] > 0:\n                    new_state.play(i + 1, cur_player)\n                    new_score, _ = self.minimax_alpha_beta(new_state, depth - 1, alpha, beta, False, 3 - cur_player)  # recursive call\n                    if new_score > value:   # maximizing the value\n                        value = new_score\n                        best_move = i + 1\n                    alpha = max(alpha, value)\n                    if beta <= alpha:  # pruning happens here\n                        break\n            return value, best_move\n        else:\n            value = math.inf\n            best_move = None\n            for i in range(state.pits_per_player + 1, len(state.board) - 1):  # generate all possible states\n                new_state = copy.deepcopy(state)\n                if new_state.board[i] > 0:\n                    new_state.play(i + 1, cur_player)\n                    new_score, _ = self.minimax_alpha_beta(new_state, depth - 1, alpha, beta, True, 3 - cur_player)  # recursive call\n                    if new_score < value:  # minimizing the value\n                        value = new_score\n                        best_move = i + 1\n                    beta = min(beta, value)\n                    if beta <= alpha:  # pruning happens here\n                        break\n            return value, best_move\n\n    def best_move(self, state, alpha_beta = False, first_player = False):\n        \n        if alpha_beta:\n            return self.minimax_alpha_beta(state, self.depth, -math.inf, math.inf, first_player, state.current_player)[1]\n        else:\n            return self.minimax(state, self.depth, first_player, state.current_player)[1]\n\n    def evaluate_state(self, state):\n        # Utility function  :- Difference between P1 mancala and p2 mancala\n        return state.board[state.p1_mancala_index] - state.board[state.p2_mancala_index]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"game = Mancala()\ngame.generate_board()\ngame.match_analysis(p1_type = 'random', p2_type = 'random')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"game = Mancala()\ngame.generate_board()\ngame.match_analysis(games = 1, p1_type = 'random', p2_type = 'minimax')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"game = Mancala()\ngame.generate_board()\ngame.match_analysis(p1_type = 'random', p2_type = 'minimax')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"game = Mancala()\ngame.generate_board()\ngame.match_analysis(p1_type = 'random', p2_type = 'alpha-beta')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"game = Mancala()\ngame.generate_board()\ngame.match_analysis(p1_type = 'random', p2_type = 'alpha-beta', p2_depth = 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"game = Mancala()\ngame.generate_board()\ngame.match_analysis(p1_type = 'minimax', p2_type = 'alpha-beta', p2_depth = 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"game = Mancala()\ngame.generate_board()\ngame.match_analysis(p1_type = 'minimax', p2_depth = 10) # In this case, p2_type will be alpha-beta","metadata":{},"execution_count":null,"outputs":[]}]}